{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-01-11T06:01:51.605540Z",
     "start_time": "2024-01-11T06:01:51.580434Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Unable to open path/to/shape_predictor_68_face_landmarks.dat",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[1], line 7\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[38;5;66;03m# Dlib's face detector and landmark predictor\u001B[39;00m\n\u001B[1;32m      6\u001B[0m detector \u001B[38;5;241m=\u001B[39m dlib\u001B[38;5;241m.\u001B[39mget_frontal_face_detector()\n\u001B[0;32m----> 7\u001B[0m predictor \u001B[38;5;241m=\u001B[39m \u001B[43mdlib\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mshape_predictor\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mpath/to/shape_predictor_68_face_landmarks.dat\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m      9\u001B[0m \u001B[38;5;66;03m# Step 1: Face extraction and key-point detection\u001B[39;00m\n\u001B[1;32m     10\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mextract_face_and_keypoints\u001B[39m(image_path):\n",
      "\u001B[0;31mRuntimeError\u001B[0m: Unable to open path/to/shape_predictor_68_face_landmarks.dat"
     ]
    }
   ],
   "source": [
    "import dlib\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Dlib's face detector and landmark predictor\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor('path/to/shape_predictor_68_face_landmarks.dat')\n",
    "\n",
    "# Step 1: Face extraction and key-point detection\n",
    "def extract_face_and_keypoints(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Detect faces in the image\n",
    "    faces = detector(gray)\n",
    "    \n",
    "    if len(faces) == 0:\n",
    "        return None, None\n",
    "    \n",
    "    # Extract facial key-points using landmark predictor\n",
    "    landmarks = predictor(gray, faces[0])\n",
    "    \n",
    "    return faces[0], landmarks\n",
    "\n",
    "# Example usage\n",
    "image_path = 'path/to/image.jpg'\n",
    "face, landmarks = extract_face_and_keypoints(image_path)\n",
    "\n",
    "# Step 2: Face alignment\n",
    "def align_face(image, landmarks):\n",
    "    # Extracting key-point coordinates\n",
    "    left_eye = (landmarks.part(36).x, landmarks.part(36).y)\n",
    "    right_eye = (landmarks.part(45).x, landmarks.part(45).y)\n",
    "    nose = (landmarks.part(30).x, landmarks.part(30).y)\n",
    "    \n",
    "    # Calculating center points\n",
    "    glabella_center = ((left_eye[0] + right_eye[0]) // 2, (left_eye[1] + right_eye[1]) // 2)\n",
    "    forehead_center = ((landmarks.part(0).x + landmarks.part(2).x) // 2, (landmarks.part(19).y + landmarks.part(24).y) // 2)\n",
    "    \n",
    "    # Constructing a triangle for angle calculation\n",
    "    triangle = np.array([forehead_center, nose, glabella_center], dtype='float32')\n",
    "    \n",
    "    # Computing rotation angle\n",
    "    angle = np.degrees(np.arctan2(glabella_center[1] - nose[1], glabella_center[0] - nose[0]))\n",
    "    \n",
    "    # Rotating the image\n",
    "    rotated_face = cv2.warpAffine(image, cv2.getRotationMatrix2D(glabella_center, angle, 1.0), (image.shape[1], image.shape[0]))\n",
    "    \n",
    "    return rotated_face\n",
    "\n",
    "# Example usage\n",
    "aligned_face = align_face(face, landmarks)\n",
    "\n",
    "# Step 3: Resizing\n",
    "def resize_image(image, size=(224, 224)):\n",
    "    return cv2.resize(image, size)\n",
    "\n",
    "# Example usage\n",
    "resized_face = resize_image(aligned_face)\n",
    "\n",
    "# Displaying the results\n",
    "cv2.imshow('Original Face', face)\n",
    "cv2.imshow('Aligned and Resized Face', resized_face)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-11T06:22:00.189221Z",
     "start_time": "2024-01-11T06:21:56.888969Z"
    }
   },
   "id": "aeb0dcbbe3abd397",
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "161b5168fb77de3c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
